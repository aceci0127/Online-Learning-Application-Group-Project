{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Online Learning Experiments - Group Project\n",
        "\n",
        "This notebook contains all experiments for the Online Learning project, organized in a modular and scalable way.\n",
        "\n",
        "## Table of Contents\n",
        "1. [Setup and Imports](#setup)\n",
        "2. [Experiment Configuration Framework](#framework)\n",
        "3. [Task 1.1: UCB1 Simple Pricing](#task1_1)\n",
        "4. [Task 1.2: Constrained UCB Pricing](#task1_2)\n",
        "5. [Task 2.1: Combinatorial UCB Multi-Product](#task2_1)\n",
        "6. [Task 3.1: Primal-Dual Non-Stationary](#task3_1)\n",
        "7. [Task 4.1: Multi-Product Primal-Dual](#task4_1)\n",
        "8. [Task 5.1: Sliding Window Non-Stationarity](#task5_1)\n",
        "\n",
        "## Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "Autoreload abilitato - i moduli verranno ricaricati automaticamente quando modificati\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "print(\"Autoreload abilitato - i moduli verranno ricaricati automaticamente quando modificati\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup completed successfully!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import custom modules\n",
        "from environments import *\n",
        "from agents import *\n",
        "from data_generators import *\n",
        "from utils import *\n",
        "from runner import *\n",
        "from plotter import *\n",
        "\n",
        "# Configure plotting\n",
        "plt.rcParams['figure.figsize'] = [12, 6]\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"Setup completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id=\"task1_1\"></a>Task 1.1: UCB1 Simple Pricing\n",
        "\n",
        "Implementation of UCB1 for the pricing problem with uniform valuations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task 1.1 - UCB1 Simple Pricing\n",
            "Prices: [0.1 0.2 0.3 0.5 0.7 0.8]\n",
            "Expected revenues: [0.09 0.16 0.21 0.25 0.21 0.16]\n",
            "Best clairvoyant price: 0.5 (idx 3)\n",
            "Running Task 1.1 - UCB1 Simple Pricing\n",
            "Horizon: 150000, Trials: 2\n",
            "Trial 1/2... "
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Task1_1_Runner.create_agent() takes 1 positional argument but 2 were given",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Run experiment\u001b[39;00m\n\u001b[32m     44\u001b[39m runner = Task1_1_Runner(config)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m result: ExperimentResult = \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m StandardPlotter.plot_experiment_results(result, show_units=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     49\u001b[39m StandardPlotter.plot_arm_distribution(result.final_agents[\u001b[32m0\u001b[39m], prices, \u001b[33m\"\u001b[39m\u001b[33mTask 1.1 - Arm Distribution\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\39340\\OneDrive\\Desktop\\OLAProject\\Online-Learning-Application-Group-Project\\runner.py:128\u001b[39m, in \u001b[36mStandardExperimentRunner.run_experiment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.config.n_trials):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.config.n_trials\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     regrets, units_sold, final_reward, agent = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_single_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m     all_regrets.append(regrets)\n\u001b[32m    130\u001b[39m     all_units_sold.append(units_sold)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\39340\\OneDrive\\Desktop\\OLAProject\\Online-Learning-Application-Group-Project\\runner.py:77\u001b[39m, in \u001b[36mStandardExperimentRunner.run_single_trial\u001b[39m\u001b[34m(self, trial)\u001b[39m\n\u001b[32m     74\u001b[39m np.random.seed(trial_seed)\n\u001b[32m     76\u001b[39m env = \u001b[38;5;28mself\u001b[39m.create_environment(trial_seed)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m agent = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m regrets = []\n\u001b[32m     80\u001b[39m units_sold = []\n",
            "\u001b[31mTypeError\u001b[39m: Task1_1_Runner.create_agent() takes 1 positional argument but 2 were given"
          ]
        }
      ],
      "source": [
        "class Task1_1_Runner(StandardExperimentRunner):\n",
        "    \"\"\"UCB1 Simple Pricing experiment runner\"\"\"\n",
        "    \n",
        "    def __init__(self, config: ExperimentConfig):\n",
        "        super().__init__(config)\n",
        "        self.prices = config.prices\n",
        "        self.expected_revenues = self.prices * (1 - self.prices)\n",
        "        self.best_idx = np.argmax(self.expected_revenues)\n",
        "        self.clairvoyant_reward_per_round = self.expected_revenues[self.best_idx]\n",
        "        \n",
        "    def create_environment(self, trial_seed: int):\n",
        "        rng = np.random.RandomState(trial_seed)\n",
        "        return PricingEnvironment(self.prices, self.config.horizon, rng=rng)\n",
        "        \n",
        "    def create_agent(self):\n",
        "        return UCB1PricingAgent(len(self.prices), self.config.horizon)\n",
        "        \n",
        "    def compute_clairvoyant_reward(self) -> float:\n",
        "        return self.clairvoyant_reward_per_round\n",
        "        \n",
        "    def extract_metrics(self, result) -> tuple[float, float]:\n",
        "        return float(result), 1.0\n",
        "\n",
        "prices = create_simple_prices()\n",
        "config = ExperimentConfig(\n",
        "    task_name=\"Task 1.1 - UCB1 Simple Pricing\",\n",
        "    horizon=150_000,\n",
        "    n_trials=2,\n",
        "    seed=18,\n",
        "    prices=prices\n",
        ")\n",
        "\n",
        "print(f\"Task 1.1 - UCB1 Simple Pricing\")\n",
        "print(f\"Prices: {prices}\")\n",
        "\n",
        "expected_revenues = prices * (1 - prices)\n",
        "best_idx = np.argmax(expected_revenues)\n",
        "best_price = prices[best_idx]\n",
        "\n",
        "print(f\"Expected revenues: {np.round(expected_revenues, 6)}\")\n",
        "print(f\"Best clairvoyant price: {best_price} (idx {best_idx})\")\n",
        "\n",
        "# Run experiment\n",
        "runner = Task1_1_Runner(config)\n",
        "result: ExperimentResult = runner.run_experiment()\n",
        "\n",
        "StandardPlotter.plot_experiment_results(result, show_units=False)\n",
        "\n",
        "StandardPlotter.plot_arm_distribution(result.final_agents[0], prices, \"Task 1.1 - Arm Distribution\")\n",
        "\n",
        "analysis = StandardAnalyzer.analyze_results(result)\n",
        "StandardAnalyzer.print_analysis(result, analysis)\n",
        "\n",
        "print(f\"\\nDetailed Results:\")\n",
        "print(f\"Expected revenues: {np.round(expected_revenues, 4)}\")\n",
        "print(f\"Empirical average rewards: {np.round(result.final_agents[0].average_rewards, 4)}\")\n",
        "\n",
        "# Store result for later comparison\n",
        "task1_1_result = result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id=\"task1_2\"></a>Task 1.2: Constrained UCB Pricing\n",
        "\n",
        "Implementation of Constrained UCB for pricing with budget constraints.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Task1_2_Runner(StandardExperimentRunner):\n",
        "    \"\"\"Constrained UCB Pricing experiment runner\"\"\"\n",
        "    \n",
        "    def __init__(self, config: ExperimentConfig):\n",
        "        super().__init__(config)\n",
        "        self.prices = config.prices\n",
        "        self.sell_probabilities = np.maximum(0, 1 - self.prices)\n",
        "        self.expected_reward = self.prices * self.sell_probabilities\n",
        "        \n",
        "        self.exp_util, self.gamma, self.exp_cost = compute_clairvoyant_single_product(\n",
        "            self.prices, self.sell_probabilities, config.budget, config.horizon\n",
        "        )\n",
        "        \n",
        "    def create_environment(self, trial_seed: int):\n",
        "        rng = np.random.RandomState(trial_seed)\n",
        "        return BudgetedPricingEnvironment(self.prices, self.config.horizon, rng=rng)\n",
        "        \n",
        "    def create_agent(self):\n",
        "        return ConstrainedUCBPricingAgent(len(self.prices), self.config.budget, self.config.horizon, alpha=1)\n",
        "        \n",
        "    def compute_clairvoyant_reward(self) -> float:\n",
        "        return self.exp_util\n",
        "        \n",
        "    def extract_metrics(self, result) -> tuple[float, float]:\n",
        "        return float(result[0]), float(result[1])\n",
        "\n",
        "prices = create_default_prices()\n",
        "config = ExperimentConfig(\n",
        "    task_name=\"Task 1.2 - Constrained UCB Pricing\",\n",
        "    horizon=10_000,\n",
        "    n_trials=3,\n",
        "    seed=18,\n",
        "    budget=4_000,\n",
        "    prices=prices\n",
        ")\n",
        "\n",
        "print(\"Task 1.2 - Constrained UCB Pricing\")\n",
        "print(f\"Prices: {len(prices)} prices from {prices[0]:.3f} to {prices[-2]:.3f}\")\n",
        "print(f\"Budget: {config.budget}, Horizon: {config.horizon}\")\n",
        "\n",
        "runner = Task1_2_Runner(config)\n",
        "\n",
        "print(f\"Sell probabilities (uniform): first 5 = {runner.sell_probabilities[:5]}\")\n",
        "print(f\"Expected rewards: first 5 = {runner.expected_reward[:5]}\")\n",
        "print(f\"Clairvoyant utility per round: {runner.exp_util:.4f}\")\n",
        "\n",
        "result = runner.run_experiment()\n",
        "\n",
        "StandardPlotter.plot_experiment_results(result, show_units=True)\n",
        "\n",
        "StandardPlotter.plot_arm_distribution(result.final_agents[0], prices, \"Task 1.2 - Arm Distribution\")\n",
        "\n",
        "analysis = StandardAnalyzer.analyze_results(result)\n",
        "StandardAnalyzer.print_analysis(result, analysis)\n",
        "\n",
        "baseline_reward = runner.exp_util * config.horizon\n",
        "print(f\"Baseline reward: {baseline_reward:.2f}\")\n",
        "\n",
        "task1_2_result = result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id=\"task2_1\"></a>Task 2.1: Combinatorial UCB Multi-Product\n",
        "\n",
        "Implementation of Constrained Combinatorial UCB for multi-product pricing with shared budget.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Task2_1_Runner(StandardExperimentRunner):\n",
        "    \"\"\"Combinatorial UCB Multi-Product experiment runner\"\"\"\n",
        "    \n",
        "    def __init__(self, config: ExperimentConfig):\n",
        "        super().__init__(config)\n",
        "        self.n_products = config.n_products\n",
        "        self.price_grid = [np.concatenate([config.prices, [1.001]]) for _ in range(self.n_products)]\n",
        "        \n",
        "        self.clair_reward, self.simplex = solve_clairvoyant_lp(self.price_grid, config.budget, config.horizon)\n",
        "        \n",
        "    def create_environment(self, trial_seed: int):\n",
        "        rng = np.random.default_rng(trial_seed)\n",
        "        return MultiProductPricingEnvironment(self.price_grid, self.config.horizon, rng=rng)\n",
        "        \n",
        "    def create_agent(self):\n",
        "        return ConstrainedCombinatorialUCBAgent(self.price_grid, self.config.budget, self.config.horizon, alpha=2)\n",
        "        \n",
        "    def compute_clairvoyant_reward(self) -> float:\n",
        "        return self.clair_reward\n",
        "        \n",
        "    def extract_metrics(self, result) -> tuple[float, float]:\n",
        "        rewards, costs = result\n",
        "        return float(np.sum(rewards)), float(np.sum(costs))\n",
        "\n",
        "N_products = 3\n",
        "price_grid = np.linspace(0, 1, 10)\n",
        "\n",
        "config = ExperimentConfig(\n",
        "    task_name=\"Task 2.1 - Combinatorial UCB Multi-Product\",\n",
        "    horizon=10_000,\n",
        "    n_trials=1,\n",
        "    seed=18,\n",
        "    budget=11_000,\n",
        "    prices=price_grid,\n",
        "    n_products=N_products\n",
        ")\n",
        "\n",
        "print(f\"Task 2.1 - Combinatorial UCB Multi-Product\")\n",
        "print(f\"Products: {N_products}, Prices per product: {len(price_grid)}\")\n",
        "print(f\"Budget: {config.budget}, Horizon: {config.horizon}\")\n",
        "\n",
        "# Run experiment\n",
        "runner = Task2_1_Runner(config)\n",
        "\n",
        "print(f\"Clairvoyant expected reward per round: {runner.clair_reward:.4f}\")\n",
        "print(f\"Simplex solution shape: {np.array(runner.simplex).shape}\")\n",
        "\n",
        "result = runner.run_experiment()\n",
        "\n",
        "StandardPlotter.plot_experiment_results(result, show_units=True)\n",
        "\n",
        "StandardPlotter.plot_arm_distribution(result.final_agents[0], runner.price_grid, \"Task 2.1 - Arm Distribution\")\n",
        "\n",
        "analysis = StandardAnalyzer.analyze_results(result)\n",
        "StandardAnalyzer.print_analysis(result, analysis)\n",
        "\n",
        "print(f\"\\nDetailed Results Task 2.1:\")\n",
        "if analysis['min_rounds'] > 0:\n",
        "    print(f\"Average regret per round: {analysis['avg_regret_per_round']:.4f}\")\n",
        "    final_units = [units[-1] if units else 0 for units in result.units_sold]\n",
        "    avg_units = np.mean(final_units)\n",
        "    print(f\"Average units sold: {avg_units:.2f}\")\n",
        "    print(f\"Budget utilization: {avg_units}/{config.budget} ({100*avg_units/config.budget:.1f}%)\")\n",
        "\n",
        "task2_1_result = result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id=\"task3_1\"></a>Task 3.1: Primal-Dual Non-Stationary Pricing\n",
        "\n",
        "Implementation of Full-Feedback Primal-Dual for non-stationary environments with adversarial shocks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Task3_1_Runner(StandardExperimentRunner):\n",
        "    \"\"\"Primal-Dual Non-Stationary Pricing experiment runner\"\"\"\n",
        "    \n",
        "    def __init__(self, config: ExperimentConfig):\n",
        "        super().__init__(config)\n",
        "        self.prices = config.prices\n",
        "        self.shock_prob = 0.0\n",
        "        self.freq = 50\n",
        "        \n",
        "    def create_environment(self, trial_seed: int):\n",
        "        rng = np.random.RandomState(trial_seed)\n",
        "        return NonStationaryBudgetedPricingEnvironment(\n",
        "            self.prices, self.config.horizon, self.shock_prob, self.freq, \n",
        "            num_regimes=10000, valuation_type='beta', rng=rng\n",
        "        )\n",
        "        \n",
        "    def create_agent(self):\n",
        "        eta = 1 / np.sqrt(self.config.horizon)\n",
        "        return FFPrimalDualPricingAgent(self.prices, self.config.horizon, self.config.budget, eta=eta)\n",
        "\n",
        "    def compute_clairvoyant_reward(self) -> float:\n",
        "        \"\"\"Compute clairvoyant reward - override for specific tasks\"\"\"\n",
        "        return 0 # We override the run_single_trial method\n",
        "\n",
        "        \n",
        "    def run_single_trial(self, trial: int):\n",
        "        \"\"\"Custom trial runner for Task 3.1 due to special full-feedback structure\"\"\"\n",
        "        trial_seed = self.config.seed + trial\n",
        "        np.random.seed(trial_seed)\n",
        "        \n",
        "        env = self.create_environment(trial_seed)\n",
        "        agent = self.create_agent()\n",
        "        \n",
        "        sell_probabilities = env.compute_sell_probabilities()\n",
        "        exp_util, gamma, exp_cost = compute_clairvoyant_single_product(\n",
        "            self.prices, sell_probabilities, self.config.budget, self.config.horizon\n",
        "        )\n",
        "        \n",
        "        if trial == 0:\n",
        "            print(f\"Clairvoyant utility: {exp_util:.4f}\")\n",
        "            print(f\"Expected cost per round: {exp_cost:.4f}\")\n",
        "            print(f\"Sell probabilities (first 5): {sell_probabilities[:5]}\")\n",
        "        \n",
        "        regrets = []\n",
        "        units_sold = []\n",
        "        cum_reward = 0.0\n",
        "        cum_regret = 0.0\n",
        "        cum_units = 0\n",
        "        \n",
        "        for t in range(self.config.horizon):\n",
        "            arm = agent.pull_arm()\n",
        "            if arm is None:\n",
        "                print(f\"Trial {trial+1}: Budget exhausted at round {t}.\")\n",
        "                break\n",
        "                \n",
        "            valuation = env.round()\n",
        "            reward, sold = agent.update(valuation)\n",
        "            \n",
        "            cum_reward += reward\n",
        "            instant_regret = exp_util - reward\n",
        "            cum_regret += instant_regret\n",
        "            cum_units += sold\n",
        "            regrets.append(cum_regret)\n",
        "            units_sold.append(int(cum_units))\n",
        "            \n",
        "        print(f\"Trial {trial+1}: Final reward = {cum_reward:.2f}, Budget remaining = {agent.inventory}\")\n",
        "        print(f\"Final pull counts: {agent.pull_counts}\")\n",
        "        print(f\"Final λ multiplier: {agent.lmbd:.4f}\", end=\" \")\n",
        "        \n",
        "        return regrets, units_sold, cum_reward, agent\n",
        "\n",
        "prices = create_default_prices()\n",
        "config = ExperimentConfig(\n",
        "    task_name=\"Task 3.1 - Primal-Dual Non-Stationary Pricing\",\n",
        "    horizon=10_000,\n",
        "    n_trials=1,\n",
        "    seed=17,\n",
        "    budget=6_000,\n",
        "    prices=prices\n",
        ")\n",
        "\n",
        "print(f\"Task 3.1 - Primal-Dual Non-Stationary Pricing\")\n",
        "print(f\"Budget: {config.budget}, Horizon: {config.horizon}\")\n",
        "print(f\"Shock probability: {0.50}, Frequency: {300}\")\n",
        "print(f\"Prices: {len(prices)} from {prices[0]:.3f} to {prices[-2]:.3f}\")\n",
        "\n",
        "runner = Task3_1_Runner(config)\n",
        "result = runner.run_experiment()\n",
        "\n",
        "StandardPlotter.plot_experiment_results(result, show_units=True)\n",
        "\n",
        "analysis = StandardAnalyzer.analyze_results(result)\n",
        "StandardAnalyzer.print_analysis(result, analysis)\n",
        "\n",
        "task3_1_result = result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 4.1: Multi-Product Primal-Dual\n",
        "\n",
        "Implementazione di Multi-Product Full-Feedback Primal-Dual per ambienti correlati multi-prodotto.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Task4_1_Runner(StandardExperimentRunner):\n",
        "    \"\"\"Multi-Product Primal-Dual experiment runner\"\"\"\n",
        "\n",
        "    def __init__(self, config: ExperimentConfig):\n",
        "        super().__init__(config)\n",
        "        self.prices = config.prices\n",
        "        self.n_products = config.n_products\n",
        "\n",
        "        self.phi = np.zeros(self.n_products)\n",
        "        self.mu0, self.A, self.f = 0.5, 0.1, 100\n",
        "        self.sigma0, self.A_sigma, self.phi_sigma, self.rho0 = 0.1, 0.1, 0, 0.6\n",
        "\n",
        "    def create_environment(self, trial_seed: int):\n",
        "        rng = np.random.default_rng(trial_seed)\n",
        "        valuation_params = {\n",
        "            'mu0': self.mu0, 'A': self.A, 'f': self.f, 'phi': self.phi,\n",
        "            'sigma0': self.sigma0, 'A_sigma': self.A_sigma, 'phi_sigma': self.phi_sigma, 'rho0': self.rho0,\n",
        "            'num_regimes': 10000\n",
        "        }\n",
        "        return MultiProductBudgetedPricingEnvironment(\n",
        "            self.prices, self.config.horizon, self.n_products, valuation_params, valuation_type='piecewise_tv', rng=rng\n",
        "        )\n",
        "\n",
        "    def create_agent(self) -> MultiProductFFPrimalDualPricingAgent:\n",
        "        eta = 1 / np.sqrt(self.config.horizon)\n",
        "        return MultiProductFFPrimalDualPricingAgent(self.prices, self.config.horizon, self.config.budget, self.n_products, eta)\n",
        "\n",
        "    def compute_clairvoyant_reward(self) -> float:\n",
        "        return 0  # We override the run_single_trial method\n",
        "\n",
        "    def run_single_trial(self, trial: int):\n",
        "        \"\"\"Custom trial runner for Task 4.1 due to special full-feedback multi-product structure\"\"\"\n",
        "        trial_seed = self.config.seed + trial\n",
        "        np.random.seed(trial_seed)\n",
        "        trial_rng = np.random.default_rng(trial_seed)\n",
        "\n",
        "        V, _ = generate_piecewise_tv_mv_gauss(\n",
        "            self.config.horizon, self.n_products, num_regimes=10000, rng=trial_rng)\n",
        "\n",
        "        exp_util, gamma, exp_cost = compute_extended_clairvoyant(\n",
        "            V, self.prices, self.config.budget)\n",
        "\n",
        "        if trial == 0:\n",
        "            print(f\"Clairvoyant reward per round: {exp_util:.4f}\")\n",
        "            print(f\"Expected cost per round: {exp_cost:.4f}\")\n",
        "            print(f\"Optimal gamma shape: {gamma.shape}\")\n",
        "            print(f\"Average gamma per product: {gamma.mean(axis=1)}\", end=\" \")\n",
        "\n",
        "        env = self.create_environment(trial_seed)\n",
        "        env.V = V\n",
        "\n",
        "        agent = self.create_agent()\n",
        "\n",
        "        regrets = []\n",
        "        units_sold = []\n",
        "        cum_reward = 0.0\n",
        "        cum_regret = 0.0\n",
        "        cum_units = 0\n",
        "\n",
        "        for t in range(self.config.horizon):\n",
        "            if agent.B < 1:\n",
        "                print(f\"Trial {trial+1}: Budget exhausted at round {t}.\")\n",
        "                break\n",
        "\n",
        "            v_t = env.round()\n",
        "            reward, sold = agent.update(v_t)\n",
        "\n",
        "            cum_reward += reward\n",
        "            instant_regret = exp_util - reward\n",
        "            cum_regret += instant_regret\n",
        "            cum_units += sold\n",
        "            regrets.append(cum_regret)\n",
        "            units_sold.append(int(cum_units))\n",
        "\n",
        "        print(f\"Trial {trial+1}: Final cumulative reward = {cum_reward:.2f}\")\n",
        "        print(f\"Trial {trial+1}: Budget remaining = {agent.B}\")\n",
        "        print(f\"Trial {trial+1}: Final λ = {agent.lmbd:.4f}\")\n",
        "\n",
        "        return regrets, units_sold, cum_reward, agent\n",
        "\n",
        "\n",
        "prices = create_default_prices()\n",
        "config = ExperimentConfig(\n",
        "    task_name=\"Task 4.1 - Multi-Product Primal-Dual\",\n",
        "    horizon=100_000,\n",
        "    n_trials=1,\n",
        "    seed=42,\n",
        "    budget=80_000,\n",
        "    prices=prices,\n",
        "    n_products=4\n",
        ")\n",
        "\n",
        "print(f\"Task 4.1 - Multi-Product Primal-Dual\")\n",
        "print(f\"Products: 4, Budget: {config.budget}, Horizon: {config.horizon}\")\n",
        "print(f\"Prices: {len(prices)} from {prices[0]:.3f} to {prices[-2]:.3f}\")\n",
        "print(f\"Correlation parameters: μ₀=0.5, ρ₀=0.6\")\n",
        "\n",
        "runner = Task4_1_Runner(config)\n",
        "result = runner.run_experiment()\n",
        "\n",
        "StandardPlotter.plot_experiment_results(result, show_units=True)\n",
        "\n",
        "analysis = StandardAnalyzer.analyze_results(result)\n",
        "StandardAnalyzer.print_analysis(result, analysis)\n",
        "\n",
        "task4_1_result = result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 5.1: Sliding Window per Non-Stazionarietà\n",
        "\n",
        "Implementazione di Constrained Combinatorial UCB con Sliding Window per adattamento locale a cambiamenti.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Task5_1_Runner(StandardExperimentRunner):\n",
        "    \"\"\"Smooth Multi-Product Pricing with Sliding Window UCB\"\"\"\n",
        "    \n",
        "    def __init__(self, config: ExperimentConfig):\n",
        "        super().__init__(config)\n",
        "        self.N_products = config.n_products\n",
        "        self.price_grid = [\n",
        "            np.concatenate([config.prices, [1.001]])\n",
        "            for _ in range(self.N_products)\n",
        "        ]\n",
        "        self.num_windows = config.n_windows\n",
        "        self.window_size = int((config.horizon * np.log(config.horizon)) ** (2/3))\n",
        "        \n",
        "        # Generate valuation data for clairvoyant computation\n",
        "        rng_val = np.random.default_rng(config.seed)\n",
        "        self.expected_means, self.V = generate_smooth_valuation_data(\n",
        "            config.horizon, K=self.num_windows, M=self.N_products,\n",
        "            max_jump=0.02, transition_frac=0.2, concentration=10, rng=rng_val\n",
        "        )\n",
        "        \n",
        "        # Compute clairvoyant reward\n",
        "        full_prices = self.price_grid[0]\n",
        "        self.clair_reward, self.simplex, self.expected_cost = compute_extended_clairvoyant(\n",
        "            self.V, full_prices, config.budget\n",
        "        )\n",
        "        \n",
        "    def create_environment(self, trial_seed: int):\n",
        "        rng = np.random.default_rng(trial_seed)\n",
        "        return SmoothMultiProductPricingEnvironment(\n",
        "            self.price_grid, self.config.horizon, valuations=self.V, rng=rng\n",
        "        )\n",
        "        \n",
        "    def create_agent(self):\n",
        "        return SlidingWindowConstrainedCombinatorialUCBAgent(\n",
        "            self.price_grid, self.config.budget, self.config.horizon, \n",
        "            window_size=self.window_size\n",
        "        )\n",
        "        \n",
        "    def compute_clairvoyant_reward(self) -> float:\n",
        "        return self.clair_reward\n",
        "        \n",
        "    def extract_metrics(self, result) -> tuple[float, float]:\n",
        "        rewards, costs = result\n",
        "        return float(np.sum(rewards)), float(np.sum(costs))\n",
        "    \n",
        "    def run_single_trial(self, trial: int):\n",
        "        \"\"\"Custom trial runner for Task 5.2 with smooth valuation data\"\"\"\n",
        "        trial_seed = self.config.seed + trial\n",
        "        np.random.seed(trial_seed)\n",
        "        \n",
        "        env = self.create_environment(trial_seed)\n",
        "        agent = self.create_agent()\n",
        "        \n",
        "        regrets = []\n",
        "        units_sold = []\n",
        "        cum_reward = 0.0\n",
        "        cum_regret = 0.0\n",
        "        cum_units = 0\n",
        "        \n",
        "        print(f\"Trial {trial+1}/{self.config.n_trials}...\")\n",
        "        \n",
        "        for t in range(self.config.horizon):\n",
        "            choice = agent.pull_arm()\n",
        "            if choice is None:\n",
        "                print(f\"Trial {trial+1}: Budget exhausted at round {t}.\")\n",
        "                break\n",
        "                \n",
        "            rewards, costs, _ = env.round(choice)  # valuations returned but not used\n",
        "            \n",
        "            # Synchronize agent time with environment's time\n",
        "            agent.t = env.t\n",
        "            agent.update(rewards, costs)\n",
        "\n",
        "            actual_rew = rewards.sum()\n",
        "            actual_units = costs.sum()\n",
        "            cum_reward += actual_rew\n",
        "            \n",
        "            # Compute instantaneous regret\n",
        "            instant_regret = self.clair_reward - actual_rew\n",
        "            cum_regret += instant_regret\n",
        "            cum_units += actual_units\n",
        "            regrets.append(cum_regret)\n",
        "            units_sold.append(int(cum_units))\n",
        "\n",
        "        print(f\"Trial {trial+1}: Final reward = {cum_reward:.2f}\")\n",
        "        print(f\"Trial {trial+1}: Budget used = {cum_units}/{self.config.budget} ({100*cum_units/self.config.budget:.1f}%)\")\n",
        "        if len(regrets) > 0:\n",
        "            regret_per_round = cum_regret / float(len(regrets))\n",
        "            print(f\"Trial {trial+1}: Final regret per round = {regret_per_round:.4f}\")\n",
        "        else:\n",
        "            print(f\"Trial {trial+1}: No regret data collected\")\n",
        "        \n",
        "        return regrets, units_sold, cum_reward, agent\n",
        "\n",
        "# Configurazione del Task 5.2\n",
        "base_prices = np.linspace(0, 1, 15)\n",
        "\n",
        "config = ExperimentConfig(\n",
        "    task_name=\"Task 5.1 - Smooth Multi-Product Pricing\",\n",
        "    horizon=50_000,\n",
        "    n_trials=1,\n",
        "    seed=18,\n",
        "    budget=55_000,\n",
        "    prices=base_prices,\n",
        "    n_products=3,\n",
        "    n_windows=4\n",
        ")\n",
        "\n",
        "print(f\"Task 5.1 - Smooth Multi-Product Pricing\")\n",
        "print(f\"Products: {config.n_products}, Temporal windows: 4\")\n",
        "print(f\"Budget: {config.budget}, Horizon: {config.horizon}\")\n",
        "print(f\"Prices per product: {len(base_prices) + 1}\")\n",
        "\n",
        "runner = Task5_1_Runner(config)\n",
        "print(f\"Clairvoyant expected reward per round: {runner.clair_reward:.4f}\")\n",
        "print(f\"Simplex: {runner.simplex}\")\n",
        "print(f\"Window size: {runner.window_size}\")\n",
        "\n",
        "result = runner.run_experiment()\n",
        "\n",
        "StandardPlotter.plot_experiment_results(result, show_units=True)\n",
        "\n",
        "StandardPlotter.plot_arm_distribution(result.final_agents[0], runner.price_grid, \"Task 5.1 - Arm Distribution\")\n",
        "\n",
        "analysis = StandardAnalyzer.analyze_results(result)\n",
        "StandardAnalyzer.print_analysis(result, analysis)\n",
        "\n",
        "task5_1_result = result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5.2 Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Task5_2_Runner(StandardExperimentRunner):\n",
        "    \"\"\"Smooth Multi-Product Pricing with Sliding Window UCB\"\"\"\n",
        "    \n",
        "    def __init__(self, config: ExperimentConfig):\n",
        "        super().__init__(config)\n",
        "        self.N_products = config.n_products\n",
        "        self.price_grid = [\n",
        "            np.concatenate([config.prices, [1.001]])\n",
        "            for _ in range(self.N_products)\n",
        "        ]\n",
        "        self.num_windows = config.n_windows\n",
        "        \n",
        "        # Generate valuation data for clairvoyant computation\n",
        "        rng_val = np.random.default_rng(config.seed)\n",
        "        self.expected_means, self.V = generate_one_sided_valuation_data(\n",
        "            config.horizon, segments=self.num_windows, products=self.N_products,\n",
        "            max_jump=0.02, transition_frac=0.2, concentration=10, rng=rng_val\n",
        "        )\n",
        "        \n",
        "        # Compute clairvoyant reward\n",
        "        full_prices = self.price_grid[0]\n",
        "        self.clair_reward, self.simplex, self.expected_cost = compute_extended_clairvoyant(\n",
        "            self.V, full_prices, config.budget\n",
        "        )\n",
        "        \n",
        "    def create_environment(self, trial_seed: int):\n",
        "        rng = np.random.default_rng(trial_seed)\n",
        "        return SmoothMultiProductPricingEnvironment(\n",
        "            self.price_grid, self.config.horizon, valuations=self.V, rng=rng\n",
        "        )\n",
        "        \n",
        "    def create_agent(self):\n",
        "        return MultiProductFFPrimalDualPricingAgent(\n",
        "            self.price_grid, self.config.horizon, self.config.budget, \n",
        "            n_products = self.N_products, eta = 1 / np.sqrt(self.config.horizon)\n",
        "        )\n",
        "        \n",
        "    def compute_clairvoyant_reward(self) -> float:\n",
        "        return self.clair_reward\n",
        "        \n",
        "    def extract_metrics(self, result) -> tuple[float, float]:\n",
        "        rewards, costs = result\n",
        "        return float(np.sum(rewards)), float(np.sum(costs))\n",
        "    \n",
        "    def run_single_trial(self, trial: int):\n",
        "        \"\"\"Custom trial runner for Task 5.2 with smooth valuation data\"\"\"\n",
        "        trial_seed = self.config.seed + trial\n",
        "        np.random.seed(trial_seed)\n",
        "        \n",
        "        env = self.create_environment(trial_seed)\n",
        "        agent = self.create_agent()\n",
        "        \n",
        "        regrets = []\n",
        "        units_sold = []\n",
        "        cum_reward = 0.0\n",
        "        cum_regret = 0.0\n",
        "        cum_units = 0\n",
        "        \n",
        "        print(f\"Trial {trial+1}/{self.config.n_trials}...\")\n",
        "        \n",
        "        for t in range(self.config.horizon):\n",
        "            choice = agent.pull_arm()\n",
        "            if choice is None:\n",
        "                print(f\"Trial {trial+1}: Budget exhausted at round {t}.\")\n",
        "                break\n",
        "                \n",
        "            rewards, costs, val = env.round(choice)  # valuations returned but not used\n",
        "            \n",
        "            # Synchronize agent time with environment's time\n",
        "            agent.t = env.t\n",
        "            agent.update(val)\n",
        "\n",
        "            actual_rew = rewards.sum()\n",
        "            actual_units = costs.sum()\n",
        "            cum_reward += actual_rew\n",
        "            \n",
        "            # Compute instantaneous regret\n",
        "            instant_regret = self.clair_reward - actual_rew\n",
        "            cum_regret += instant_regret\n",
        "            cum_units += actual_units\n",
        "            regrets.append(cum_regret)\n",
        "            units_sold.append(int(cum_units))\n",
        "\n",
        "        print(f\"Trial {trial+1}: Final reward = {cum_reward:.2f}\")\n",
        "        print(f\"Trial {trial+1}: Budget used = {cum_units}/{self.config.budget} ({100*cum_units/self.config.budget:.1f}%)\")\n",
        "        if regrets is not None and len(regrets) > 0:\n",
        "            regret_per_round = cum_regret / float(len(regrets))\n",
        "            print(f\"Trial {trial+1}: Final regret per round = {regret_per_round:.4f}\")\n",
        "        else:\n",
        "            print(f\"Trial {trial+1}: No regret data collected\")\n",
        "        \n",
        "        return regrets, units_sold, cum_reward, agent\n",
        "\n",
        "# Configurazione del Task 5.2\n",
        "base_prices = np.linspace(0, 1, 15)\n",
        "\n",
        "config = ExperimentConfig(\n",
        "    task_name=\"Task 5.2 - Smooth Multi-Product Pricing\",\n",
        "    horizon=10_000,\n",
        "    n_trials=1,\n",
        "    seed=18,\n",
        "    budget=10_000,\n",
        "    prices=base_prices,\n",
        "    n_products=3,\n",
        "    n_windows=4\n",
        ")\n",
        "\n",
        "print(f\"Task 5.2 - Smooth Multi-Product Pricing\")\n",
        "print(f\"Products: {config.n_products}, Temporal windows: 4\")\n",
        "print(f\"Budget: {config.budget}, Horizon: {config.horizon}\")\n",
        "print(f\"Prices per product: {len(base_prices) + 1}\")\n",
        "\n",
        "runner = Task5_2_Runner(config)\n",
        "print(f\"Clairvoyant expected reward per round: {runner.clair_reward:.4f}\")\n",
        "print(f\"Simplex: {runner.simplex}\")\n",
        "\n",
        "\n",
        "result = runner.run_experiment()\n",
        "\n",
        "StandardPlotter.plot_experiment_results(result, show_units=True)\n",
        "\n",
        "if result.final_agents:\n",
        "    StandardPlotter.plot_arm_distribution(result.final_agents[0], base_prices, \"Task 5.2 - Arm Distribution\")\n",
        "\n",
        "analysis = StandardAnalyzer.analyze_results(result)\n",
        "StandardAnalyzer.print_analysis(result, analysis)\n",
        "\n",
        "task5_1_result = result"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
